{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4aeae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/05 06:00:36 WARN Utils: Your hostname, sunghwanui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 172.16.227.180 instead (on interface en0)\n",
      "22/10/05 06:00:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/05 06:00:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pyspark1\").master('local[*]').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e1d45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital(str):\n",
    "    result = \"\"\n",
    "#     words = str.spilt(\" \")\n",
    "    for ward in words:\n",
    "        result = result + word[0:1].upper() + word[1:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a8966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test5.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test5.txt\n",
    "good morning\n",
    "danny\n",
    "I love you danny\n",
    "how are you?\n",
    "are you good?\n",
    "good good good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3921b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morning',\n",
       " 'danny',\n",
       " 'I love you danny',\n",
       " 'how are you?',\n",
       " 'are you good?',\n",
       " 'good good good']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "temp = os.path.abspath('./test5.txt')\n",
    "data = sc.textFile(temp)\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd06894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOOD MORNING',\n",
       " 'DANNY',\n",
       " 'I LOVE YOU DANNY',\n",
       " 'HOW ARE YOU?',\n",
       " 'ARE YOU GOOD?',\n",
       " 'GOOD GOOD GOOD']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x : x.upper()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87e0937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                word|count|\n",
      "+--------------------+-----+\n",
      "|                good|    1|\n",
      "|                    | 5219|\n",
      "|             General|    1|\n",
      "|            Commands|    1|\n",
      "|              Manual|    1|\n",
      "|             FIND(1)|    1|\n",
      "|    f\\bfi\\bin\\bnd\\bd|   38|\n",
      "|                walk|    1|\n",
      "|                   ||   10|\n",
      "|            -\\b-L\\bL|    7|\n",
      "|           -\\b-P\\bP]|    2|\n",
      "|           [-\\b-f\\bf|    1|\n",
      "|    _\\bp_\\ba_\\bt_\\bh|    3|\n",
      "|        _\\b._\\b._\\b.|    1|\n",
      "|[_\\be_\\bx_\\bp_\\br...|    2|\n",
      "|            -\\b-f\\bf|    2|\n",
      "|                 The|   41|\n",
      "|           directory|   12|\n",
      "|                tree|    2|\n",
      "|             listed,|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = sc.textFile('./sample.txt')\n",
    "df = data.flatMap(lambda x : x.split(\" \")).map(lambda x: (x,1)).reduceByKey(lambda x,y:x+y).collect()\n",
    "df = spark.createDataFrame(df, schema=['word', 'count'])\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58aca565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "|count|            word|\n",
      "+-----+----------------+\n",
      "| 5219|                |\n",
      "|  271|             the|\n",
      "|  106|              is|\n",
      "|  100|              to|\n",
      "|   76|              of|\n",
      "|   68|               a|\n",
      "|   66|            file|\n",
      "|   60|             and|\n",
      "|   58|              if|\n",
      "|   49|              in|\n",
      "|   43|             are|\n",
      "|   41|              be|\n",
      "|   41|             The|\n",
      "|   40|         primary|\n",
      "|   39|              as|\n",
      "|   39|            time|\n",
      "|   38|f\\bfi\\bin\\bnd\\bd|\n",
      "|   33|              by|\n",
      "|   32|             not|\n",
      "|   30|            _\\bn|\n",
      "+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('count','word').orderBy(col('count').desc())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73e24817",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = df.first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61c80fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|count| word|\n",
      "+-----+-----+\n",
      "|    1|found|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((col(\"count\") == \"1\") & (col(\"word\") ==\"found\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0ff4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"james hon\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"michael jj\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"robert rt\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"daria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"aaman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"ccott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"hen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"deff  ll\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"aumar  mo\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f2b4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|    james hon|     Sales|   NY| 90000| 34|10000|\n",
      "|   michael jj|     Sales|   NY| 86000| 56|20000|\n",
      "|    robert rt|     Sales|   CA| 81000| 30|23000|\n",
      "|        daria|   Finance|   CA| 90000| 24|23000|\n",
      "|        aaman|   Finance|   CA| 99000| 40|24000|\n",
      "|        ccott|   Finance|   NY| 83000| 36|19000|\n",
      "|          hen|   Finance|   NY| 79000| 53|15000|\n",
      "|     deff  ll| Marketing|   CA| 80000| 25|18000|\n",
      "|    aumar  mo| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(simpleData, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bf7b19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+-------------+\n",
      "|employee_name|department|state|salary|age|bonus|double salary|\n",
      "+-------------+----------+-----+------+---+-----+-------------+\n",
      "|    james hon|     Sales|   NY| 90000| 34|10000|       180000|\n",
      "|   michael jj|     Sales|   NY| 86000| 56|20000|       172000|\n",
      "|    robert rt|     Sales|   CA| 81000| 30|23000|       162000|\n",
      "|        daria|   Finance|   CA| 90000| 24|23000|       180000|\n",
      "|        aaman|   Finance|   CA| 99000| 40|24000|       198000|\n",
      "|        ccott|   Finance|   NY| 83000| 36|19000|       166000|\n",
      "|          hen|   Finance|   NY| 79000| 53|15000|       158000|\n",
      "|     deff  ll| Marketing|   CA| 80000| 25|18000|       160000|\n",
      "|    aumar  mo| Marketing|   NY| 91000| 50|21000|       182000|\n",
      "+-------------+----------+-----+------+---+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"double salary\", lit(col(\"salary\") * 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0a916f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "new_column1 = expr(\"\"\"\n",
    "IF (state = 'NY', 1, IF(department = 'Sales',2,0))\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8c3163cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+----+\n",
      "|employee_name|department|state|salary|age|bonus|new1|\n",
      "+-------------+----------+-----+------+---+-----+----+\n",
      "|    james hon|     Sales|   NY| 90000| 34|10000|   1|\n",
      "|   michael jj|     Sales|   NY| 86000| 56|20000|   1|\n",
      "|    robert rt|     Sales|   CA| 81000| 30|23000|   2|\n",
      "|        daria|   Finance|   CA| 90000| 24|23000|   0|\n",
      "|        aaman|   Finance|   CA| 99000| 40|24000|   0|\n",
      "|        ccott|   Finance|   NY| 83000| 36|19000|   1|\n",
      "|          hen|   Finance|   NY| 79000| 53|15000|   1|\n",
      "|     deff  ll| Marketing|   CA| 80000| 25|18000|   0|\n",
      "|    aumar  mo| Marketing|   NY| 91000| 50|21000|   1|\n",
      "+-------------+----------+-----+------+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"new1\", new_column1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "002cce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "new_column2= when(col('state') == 'NY',1)\\\n",
    "            .when(col('department')=='Sales',2)\\\n",
    "            .otherwise(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0e563946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+----+\n",
      "|employee_name|department|state|salary|age|bonus|new2|\n",
      "+-------------+----------+-----+------+---+-----+----+\n",
      "|    james hon|     Sales|   NY| 90000| 34|10000|   1|\n",
      "|   michael jj|     Sales|   NY| 86000| 56|20000|   1|\n",
      "|    robert rt|     Sales|   CA| 81000| 30|23000|   2|\n",
      "|        daria|   Finance|   CA| 90000| 24|23000|   0|\n",
      "|        aaman|   Finance|   CA| 99000| 40|24000|   0|\n",
      "|        ccott|   Finance|   NY| 83000| 36|19000|   1|\n",
      "|          hen|   Finance|   NY| 79000| 53|15000|   1|\n",
      "|     deff  ll| Marketing|   CA| 80000| 25|18000|   0|\n",
      "|    aumar  mo| Marketing|   NY| 91000| 50|21000|   1|\n",
      "+-------------+----------+-----+------+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('new2', new_column2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d92aa852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+----+\n",
      "|employee_name|department|state|salary|age|bonus|new3|\n",
      "+-------------+----------+-----+------+---+-----+----+\n",
      "|    james hon|     Sales|   NY| 90000| 34|10000|   3|\n",
      "|   michael jj|     Sales|   NY| 86000| 56|20000|   3|\n",
      "|    robert rt|     Sales|   CA| 81000| 30|23000|   3|\n",
      "|        daria|   Finance|   CA| 90000| 24|23000|   3|\n",
      "|        aaman|   Finance|   CA| 99000| 40|24000|   3|\n",
      "|        ccott|   Finance|   NY| 83000| 36|19000|   3|\n",
      "|          hen|   Finance|   NY| 79000| 53|15000|   3|\n",
      "|     deff  ll| Marketing|   CA| 80000| 25|18000|   3|\n",
      "|    aumar  mo| Marketing|   NY| 91000| 50|21000|   3|\n",
      "+-------------+----------+-----+------+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"new3\", lit(3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6d3d3018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Finance', 10), ('Marketing', 20), ('Sales', 30), ('IT', 40)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "rdd = sc.parallelize(dept)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e2ac6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|       _1| _2|\n",
      "+---------+---+\n",
      "|  Finance| 10|\n",
      "|Marketing| 20|\n",
      "|    Sales| 30|\n",
      "|       IT| 40|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "30e22b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3906b828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "df = rdd.toDF(deptColumns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8f4c1bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "72b1799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(rdd, deptColumns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9c12f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "38a6c64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Row(dept_name='Sales', dept_id=30)\n",
      "Row(dept_name='Marketing', dept_id=20)\n",
      "Row(dept_name='Finance', dept_id=10)\n",
      "Row(dept_name='IT', dept_id=40)\n"
     ]
    }
   ],
   "source": [
    "df.foreach(lambda x : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3e8d178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Row(dept_name='IT', dept_id=40)\n",
      "Row(dept_name='Finance', dept_id=10)\n",
      "Row(dept_name='Sales', dept_id=30)\n",
      "Row(dept_name='Marketing', dept_id=20)\n"
     ]
    }
   ],
   "source": [
    "df.foreach(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c7103a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.types.Row'>\n",
      "<class 'pyspark.sql.types.Row'>\n",
      "<class 'pyspark.sql.types.Row'>\n",
      "<class 'pyspark.sql.types.Row'>\n"
     ]
    }
   ],
   "source": [
    "a = df.foreach(lambda x: print(type(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbe07140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital(x):\n",
    "    result = \"\"\n",
    "    x = x.split(\" \")\n",
    "    for word in x:\n",
    "        result = result + word[0:1].upper() + word[1:]\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24e05f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "capUDF = udf(lambda x : capital(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "372f5d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|employee_name|department|\n",
      "+-------------+----------+\n",
      "|     JamesHon|     Sales|\n",
      "|    MichaelJj|     Sales|\n",
      "|     RobertRt|     Sales|\n",
      "|        Daria|   Finance|\n",
      "|        Aaman|   Finance|\n",
      "|        Ccott|   Finance|\n",
      "|          Hen|   Finance|\n",
      "|       DeffLl| Marketing|\n",
      "|      AumarMo| Marketing|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(capUDF(col(\"employee_name\")).alias(\"employee_name\"), col(\"department\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d0aaa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|concat(employee_name,  - , department)|\n",
      "+--------------------------------------+\n",
      "|                     james hon - Sales|\n",
      "|                    michael jj - Sales|\n",
      "|                     robert rt - Sales|\n",
      "|                       daria - Finance|\n",
      "|                       aaman - Finance|\n",
      "|                       ccott - Finance|\n",
      "|                         hen - Finance|\n",
      "|                  deff  ll - Marketing|\n",
      "|                  aumar  mo - Marke...|\n",
      "+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat,lit\n",
    "\n",
    "df.select(concat(col(\"employee_name\"),lit(' - '), col(\"department\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f903aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               name|\n",
      "+-------------------+\n",
      "|    james hon,Sales|\n",
      "|   michael jj,Sales|\n",
      "|    robert rt,Sales|\n",
      "|      daria,Finance|\n",
      "|      aaman,Finance|\n",
      "|      ccott,Finance|\n",
      "|        hen,Finance|\n",
      "| deff  ll,Marketing|\n",
      "|aumar  mo,Marketing|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "df.select(concat_ws(\",\",col(\"employee_name\"),col(\"department\")).alias(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2856abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+\n",
      "|               name|double salary|\n",
      "+-------------------+-------------+\n",
      "| james hon good guy|     90000000|\n",
      "|michael jj good guy|     86000000|\n",
      "| robert rt good guy|     81000000|\n",
      "|     daria good guy|     90000000|\n",
      "|     aaman good guy|     99000000|\n",
      "|     ccott good guy|     83000000|\n",
      "|       hen good guy|     79000000|\n",
      "|  deff  ll good guy|     80000000|\n",
      "| aumar  mo good guy|     91000000|\n",
      "+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(concat(col(\"employee_name\"),lit(\" good guy\")).alias(\"name\"), lit(col(\"salary\")*1000).alias(\"double salary\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "226069d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['james hon',\n",
       " 'michael jj',\n",
       " 'robert rt',\n",
       " 'daria',\n",
       " 'aaman',\n",
       " 'ccott',\n",
       " 'hen',\n",
       " 'deff  ll',\n",
       " 'aumar  mo']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f1b3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.rdd.map(lambda x: x[\"employee_name\"]+\" , \"+x[\"department\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9808d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  _1|\n",
      "+--------------------+\n",
      "|   james hon , Sales|\n",
      "|  michael jj , Sales|\n",
      "|   robert rt , Sales|\n",
      "|     daria , Finance|\n",
      "|     aaman , Finance|\n",
      "|     ccott , Finance|\n",
      "|       hen , Finance|\n",
      "|deff  ll , Marketing|\n",
      "|aumar  mo , Marke...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd.collect()\n",
    "rdd.map(lambda x : (x,)).toDF().show()\n",
    "# rdd.toDF([\"name\",\"df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2eeaf1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('james hon , Sales',),\n",
       " ('michael jj , Sales',),\n",
       " ('robert rt , Sales',),\n",
       " ('daria , Finance',),\n",
       " ('aaman , Finance',),\n",
       " ('ccott , Finance',),\n",
       " ('hen , Finance',),\n",
       " ('deff  ll , Marketing',),\n",
       " ('aumar  mo , Marketing',)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x : (x,)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a31236d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5p/l3b0fr1x5wn7450vgnp88r080000gn/T/ipykernel_1276/3360359090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'employee_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapital\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df.select(col('employee_name').map(capital)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4300d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f7b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68ba65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90f1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567caa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e8c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de540db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/04 06:04:21 WARN Utils: Your hostname, sunghwanui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 172.16.227.180 instead (on interface en0)\n",
      "22/10/04 06:04:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/04 06:04:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf3bba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.startTime', '1664881461943'),\n",
       " ('spark.driver.host', '172.16.227.180'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/Users/sunghwanki/Desktop/Project/Python_Advance/Pyspark/spark-warehouse'),\n",
       " ('spark.app.name', 'test'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.port', '51419'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1664881463505'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7998c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.range(1,5)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ad1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://172.16.227.180:4040\n",
      "local-1664881463505\n",
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(sc.uiWebUrl)\n",
    "print(sc.applicationId)\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0994baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sunghwanki/Desktop/Project/Python_Advance/Pyspark\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b082817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sunghwanki/Desktop/Project/Python_Advance/Pyspark/sample.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good evening']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# tempdir = os.path.abspath('./sample.txt')\n",
    "tempdir = os.path.join('/Users/sunghwanki/Desktop/Project/Python_Advance/Pyspark','sample.txt')\n",
    "print(tempdir)\n",
    "with open(tempdir, 'w') as f:\n",
    "    f.write(\"good evening\")\n",
    "    \n",
    "\n",
    "rdd = sc.textFile('./sample.txt')\n",
    "rdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a3547ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macOS 12.5                       March 13, 2021                       macOS 12.5',\n",
       " 'good eveningFIND(1)                      General Commands Manual                     FIND(1)',\n",
       " 'S\\x08SY\\x08YN\\x08NO\\x08OP\\x08PS\\x08SI\\x08IS\\x08S',\n",
       " 'S\\x08ST\\x08TA\\x08AN\\x08ND\\x08DA\\x08AR\\x08RD\\x08DS\\x08S',\n",
       " 'S\\x08SE\\x08EE\\x08E A\\x08AL\\x08LS\\x08SO\\x08O',\n",
       " 'P\\x08PR\\x08RI\\x08IM\\x08MA\\x08AR\\x08RI\\x08IE\\x08ES\\x08S',\n",
       " 'O\\x08OP\\x08PE\\x08ER\\x08RA\\x08AT\\x08TO\\x08OR\\x08RS\\x08S',\n",
       " 'N\\x08NA\\x08AM\\x08ME\\x08E',\n",
       " 'H\\x08HI\\x08IS\\x08ST\\x08TO\\x08OR\\x08RY\\x08Y',\n",
       " 'E\\x08EX\\x08XA\\x08AM\\x08MP\\x08PL\\x08LE\\x08ES\\x08S']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!man find >> ./sample.txt\n",
    "rdd = sc.textFile('./sample.txt')\n",
    "rdd.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8496f8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]\n"
     ]
    }
   ],
   "source": [
    "myList = [i for i in range(1,100) if i % 2 == 0]\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82885532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(myList)\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c6fe06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./sample1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sample1.txt\n",
    "my name is good\n",
    "good name is my name\n",
    "how are you?\n",
    "okay?\n",
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e859d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 3),\n",
       " ('is', 2),\n",
       " ('good', 3),\n",
       " ('are', 1),\n",
       " ('you?', 1),\n",
       " ('my', 2),\n",
       " ('how', 1),\n",
       " ('okay?', 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd = sc.textFile(os.path.abspath('./sample1.txt'))\n",
    "myRdd = myRdd.flatMap(lambda x: x.split(\" \")).map(lambda word:(word,1)).reduceByKey(lambda x,y: x+y)\n",
    "myRdd.collect()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e75bc096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 3\n",
      "is: 2\n",
      "good: 3\n",
      "are: 1\n",
      "you?: 1\n",
      "my: 2\n",
      "how: 1\n",
      "okay?: 1\n"
     ]
    }
   ],
   "source": [
    "output = myRdd.collect()\n",
    "for (word,count) in output:\n",
    "    print(\"%s: %i\"% (word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "168f9681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('name', 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8d84b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 3), ('is', 2), ('good', 3)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a8a3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./test.txt\n",
    "good morning\n",
    "this is new day\n",
    "I love so much\n",
    "I am good\n",
    "you are sunset\n",
    "morning\n",
    "good \n",
    "bad\n",
    "sunset\n",
    "sunrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e30a8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good : 3\n",
      "this : 1\n",
      "is : 1\n",
      "new : 1\n",
      "love : 1\n",
      "am : 1\n",
      "are : 1\n",
      "sunset : 2\n",
      " : 1\n",
      "morning : 2\n",
      "day : 1\n",
      "I : 2\n",
      "so : 1\n",
      "much : 1\n",
      "you : 1\n",
      "bad : 1\n",
      "sunrise : 1\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(os.path.abspath('./test.txt'))\n",
    "rdd = rdd.flatMap(lambda x : x.split(\" \")).map(lambda x: (x,1)).reduceByKey(lambda x,y:x+y)\n",
    "mylist = rdd.collect()\n",
    "for a,b in mylist:\n",
    "    print('%s : %i'%(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61537e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd = sc.parallelize(dataList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc2708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e66c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fceddbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906f5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52820fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30dfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f543573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc65e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(simpleData, schema=columns)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff8a1e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3e41440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0efb2128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"department\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "776025ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"department\",\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94a0cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.sort(col(\"state\"), col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb868d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"state\"), col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddacff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select * from EMP order by state, salary desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65055659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+\n",
      "|        _1|                 _2|                  _3|\n",
      "+----------+-------------------+--------------------+\n",
      "|     James|      [Java, Scala]|{eye -> brown, ha...|\n",
      "|   Michael|[Spark, Java, null]|{eye -> null, hai...|\n",
      "|    Robert|         [CSharp, ]|{eye -> , hair ->...|\n",
      "|Washington|               null|                null|\n",
      "| Jefferson|             [1, 2]|                  {}|\n",
      "+----------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arrayData = [\n",
    "        ('James',['Java','Scala'],{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',['Spark','Java',None],{'hair':'brown','eye':None}),\n",
    "        ('Robert',['CSharp',''],{'hair':'red','eye':''}),\n",
    "        ('Washington',None,None),\n",
    "        ('Jefferson',['1','2'],{})]\n",
    "\n",
    "df = spark.createDataFrame(arrayData)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abd9d2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+\n",
      "|      name|          knowledge|            property|\n",
      "+----------+-------------------+--------------------+\n",
      "|     James|      [Java, Scala]|{eye -> brown, ha...|\n",
      "|   Michael|[Spark, Java, null]|{eye -> null, hai...|\n",
      "|    Robert|         [CSharp, ]|{eye -> , hair ->...|\n",
      "|Washington|               null|                null|\n",
      "| Jefferson|             [1, 2]|                  {}|\n",
      "+----------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(arrayData, schema = ['name', 'knowledge', 'property'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e23c713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='James', knowledge=['Java', 'Scala'], property={'eye': 'brown', 'hair': 'black'}),\n",
       " Row(name='Michael', knowledge=['Spark', 'Java', None], property={'eye': None, 'hair': 'brown'}),\n",
       " Row(name='Robert', knowledge=['CSharp', ''], property={'eye': '', 'hair': 'red'}),\n",
       " Row(name='Washington', knowledge=None, property=None),\n",
       " Row(name='Jefferson', knowledge=['1', '2'], property={})]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b08357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- knowledge: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- property: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b5561a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     name|   col|\n",
      "+---------+------+\n",
      "|    James|  Java|\n",
      "|    James| Scala|\n",
      "|  Michael| Spark|\n",
      "|  Michael|  Java|\n",
      "|  Michael|  null|\n",
      "|   Robert|CSharp|\n",
      "|   Robert|      |\n",
      "|Jefferson|     1|\n",
      "|Jefferson|     2|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df2 = df.select(\"name\", explode(\"knowledge\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e9c87f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interview', 'interviewbit']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = sc.parallelize (\n",
    "  [\"pyspark\", \n",
    "  \"interview\", \n",
    "  \"questions\", \n",
    "  \"at\", \n",
    "  \"interviewbit\"]\n",
    ")\n",
    "\n",
    "filtered = words_list.filter(lambda x : 'interview' in x)\n",
    "filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd78ed61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37c244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90396a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e18f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfae1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a7f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed9d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/03 06:33:58 WARN Utils: Your hostname, sunghwanui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 172.16.227.180 instead (on interface en0)\n",
      "22/10/03 06:33:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/03 06:33:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.227.180:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark-test>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "sc = SparkContext(master='local', appName='pyspark-test')\n",
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73fb90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.driver.port', '49503'),\n",
       " ('spark.driver.host', '172.16.227.180'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'pyspark-test'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1664796841274'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.startTime', '1664796839628')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbfea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf235ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.227.180:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=test>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.setAppName(\"test\").setMaster(\"local\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86e3971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/03 07:18:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.227.180:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>session_test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ab16d90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"session_test\").master('local[*]').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9ce9efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.227.180:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>session_test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=session_test>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b5b5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'session_test'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07a6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66c04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.range(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95642236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccac14d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local-1664797151878'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f972c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://172.16.227.180:4040'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09a13e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957e4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.abspath('./sample_1.txt')\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    f.write(\"good morning\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8aab756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sunghwanki/Desktop/Project/Python_Advance/Pyspark/sample_1.txt\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4f8315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morning']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('./sample_1.txt')\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0be351ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList=[1,2,3,4,5]\n",
    "myRdd = sc.parallelize(myList)\n",
    "myRdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7f98139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcb06ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0519497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1bcc70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./sample_2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sample_2.txt\n",
    "hi my name is danny\n",
    "nice meet you\n",
    "good morning\n",
    "good evening\n",
    "the king of kings\n",
    "do you know me?\n",
    "gogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c39ea601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi my name is danny\r\n",
      "nice meet you\r\n",
      "good morning\r\n",
      "good evening\r\n",
      "the king of kings\r\n",
      "do you know me?\r\n",
      "gogo\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./sample_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a51f1133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "./sample_2.txt MapPartitionsRDD[15] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd = sc.textFile('./sample_2.txt')\n",
    "myRdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "359b16b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi my name is danny'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc384396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the king of kings', 'nice meet you', 'hi my name is danny']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65cfd0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi my name is danny',\n",
       " 'nice meet you',\n",
       " 'good morning',\n",
       " 'good evening',\n",
       " 'the king of kings',\n",
       " 'do you know me?',\n",
       " 'gogo']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f7cd602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c2e2fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi my name is danny',\n",
       " 'nice meet you',\n",
       " 'good morning',\n",
       " 'good evening',\n",
       " 'the king of kings']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7a66827",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRdd1=[a for a in range(20)]\n",
    "myRdd2= sc.parallelize(myRdd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ff5645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5086cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc4b69a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(myRdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0a851c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[23] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sub(n):\n",
    "    return n-1\n",
    "\n",
    "subRdd = myRdd2.map(sub)\n",
    "subRdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a68e9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac57df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg’s\n",
      "Alice’s Adventures in Wonderland\n",
      "Project Gutenberg’s\n",
      "Adventures in Wonderland\n",
      "Project Gutenberg’s\n"
     ]
    }
   ],
   "source": [
    "data = [\"Project Gutenberg’s\",\n",
    "        \"Alice’s Adventures in Wonderland\",\n",
    "        \"Project Gutenberg’s\",\n",
    "        \"Adventures in Wonderland\",\n",
    "        \"Project Gutenberg’s\"]\n",
    "\n",
    "rdd = sc.parallelize(data)\n",
    "for i in rdd.collect():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e4b2dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Gutenberg’s',\n",
       " 'Alice’s Adventures in Wonderland',\n",
       " 'Project Gutenberg’s',\n",
       " 'Adventures in Wonderland',\n",
       " 'Project Gutenberg’s']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e8bad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub2(n):\n",
    "    return n.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80c56d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project',\n",
       " 'Gutenberg’s',\n",
       " 'Alice’s',\n",
       " 'Adventures',\n",
       " 'in',\n",
       " 'Wonderland',\n",
       " 'Project',\n",
       " 'Gutenberg’s',\n",
       " 'Adventures',\n",
       " 'in',\n",
       " 'Wonderland',\n",
       " 'Project',\n",
       " 'Gutenberg’s']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.flatMap(sub2)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0c704b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project',\n",
       " 'Gutenberg’s',\n",
       " 'Alice’s',\n",
       " 'Adventures',\n",
       " 'in',\n",
       " 'Wonderland',\n",
       " 'Project',\n",
       " 'Gutenberg’s',\n",
       " 'Adventures',\n",
       " 'in',\n",
       " 'Wonderland',\n",
       " 'Project',\n",
       " 'Gutenberg’s']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = rdd.flatMap(lambda x:x.split(\" \"))\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57c67f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "886f246b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.227.180:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>session_test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ab16d90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1801bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37801182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['interview', 'interviewbit']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = sc.parallelize (\n",
    "  [\"pyspark\", \n",
    "  \"interview\", \n",
    "  \"questions\", \n",
    "  \"at\", \n",
    "  \"interviewbit\"]\n",
    ")\n",
    "\n",
    "filtered_words = words_list.filter(lambda x: 'interview' in x)\n",
    "filtered_words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed1f190f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2492eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words.collect()[0] = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5f335ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interview', 'interviewbit']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab50d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
